{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch C++ Frontend\n",
    "\n",
    "If you are an enthusiast/intermediate/expert in ML/AI/DeepLearning , you will already know something (or lot of things) about Pytorch. In this blog we take a step back and discuss and learn about different ways or frontends which you can use to build the Pytorch model. To be more speicific, we focus our attention on using Pytorch's C++ frontend capabilities.\n",
    "\n",
    "In this blog we try 100% hands on approach to get to the bottom of how things can be done using C++ frontend. Here is the official blog which will explain why one would need the C++ models than the python models. \n",
    "\n",
    "Here is some general caveat before we dive in.\n",
    "\n",
    "* We assume reader has atleaset some basic programming knowledge in C/C++ and python.\n",
    "* This blog is **NOT** a C++ language tutorial. But rather a tutorial which explains how to use or implement the pytorch models using C++.\n",
    "\n",
    "Here is a quick peek at what to expect out of this blog and upcoming blogs. \n",
    "\n",
    "I try to break it in to 4 different logical parts\n",
    "\n",
    "* Inital setup and building the C++ code.\n",
    "* Weights-Biases and  Perceptrons from scratch. Using Pytorch Tensors.\n",
    "* MNIST from simple Perceptrons.\n",
    "* Implement a CNN for CIFAR-10 dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial setup.\n",
    "\n",
    "To work with C++ frontend we need the pytorch libraries. Let us see how to [install](https://pytorch.org/cppdocs/installing.html) the same.\n",
    "\n",
    "* First download the libraries\n",
    "\n",
    "```\n",
    "wget https://download.pytorch.org/libtorch/nightly/cpu/libtorch-shared-with-deps-latest.zip\n",
    "\n",
    "```\n",
    "\n",
    "* Extract the libs\n",
    "\n",
    "```\n",
    "unzip libtorch-shared-with-deps-latest.zip -d /opt/pytorch\n",
    "```\n",
    "\n",
    "Notice that we are extracting the libs to the path **/opt/pytorch/**. This is just for our convenience. You can extract it where ever you want. This approach has some slight advantage, which we see later.\n",
    "\n",
    "That's it it is as simple as that. Now let us try to do some basic operations in C++.\n",
    "\n",
    "**NOTE: You can also build the libpytorch libs from the source and install. Which we will not cover here.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us use this small piece of code written is python to understand and build our model using C++ frontend.\n",
    "\n",
    "### Tensor creation using Pytorch \n",
    "\n",
    "### Python frontend:\n",
    "\n",
    "\n",
    "```python\n",
    "# First, import PyTorch\n",
    "import torch\n",
    "\n",
    "### Generate some data\n",
    "torch.manual_seed(7) # Set the random seed so things are predictable\n",
    "\n",
    "# Features are 5 random normal variables\n",
    "features = torch.randn((1, 5))\n",
    "print(features)\n",
    "\n",
    "############# OUTPUT #################\n",
    "\n",
    "tensor([[-0.1468,  0.7861,  0.9468, -1.1143,  1.6908]])\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us write the equivalent code in C++ and compile and check our results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C++ frontend:\n",
    "```cpp\n",
    "// main.cpp\n",
    "#include <torch/torch.h>\n",
    "#include <ATen/Context.h>\n",
    "#include <iostream>\n",
    "\n",
    "int main()\n",
    "{\n",
    "  // Seed for Random number\n",
    "  torch::manual_seed(9);\n",
    "  torch::Tensor features = torch::rand({1, 5});\n",
    "  std::cout << \"features = \" << features << \"\\n\";\n",
    "}\n",
    "\n",
    "################ OUTPUT #######################\n",
    "\n",
    "features =  0.6558  0.3020  0.4799  0.7774  0.9180\n",
    "[ Variable[CPUFloatType]{1,5} ]\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you already understood the above code great job! You can skip this section and move to next one where we discuss about compiling and linking the pytorch libs to generate a binary.\n",
    "\n",
    "For those of you who need some more help. Let us break down the code line by line\n",
    "\n",
    "As you all know we just import the python module as follows.\n",
    "\n",
    "```python\n",
    "import torch\n",
    "```\n",
    "\n",
    "Similarly in C++ we use the include statement as follows to include the required headers. Which is similar to **import** in python\n",
    "\n",
    "```cpp\n",
    "#include <torch/torch.h>\n",
    "#include <ATen/Context.h>\n",
    "```\n",
    "\n",
    "Now, we seed our randon number in python as follows.\n",
    "\n",
    "```python\n",
    "### Generate some data\n",
    "torch.manual_seed(7) # Set the random seed so things are predictable\n",
    "```\n",
    "\n",
    "Similarly we seed the randon number geneator as follows in C++.\n",
    "```cpp\n",
    "  // Seed for Random number\n",
    "  torch::manual_seed(9);\n",
    "```\n",
    "\n",
    "\n",
    "Now let us generate a **Tensor** of one-Dimention. \n",
    "```python\n",
    "# Features are 5 random normal variables\n",
    "features = torch.randn((1, 5))\n",
    "print(features)\n",
    "```\n",
    "\n",
    "This is how you generate a **Tensor** of one-Dimention using C++ code. And as usual we use **std::cout** to print the results to console.\n",
    "```cpp\n",
    "  torch::Tensor features = torch::rand({1, 5});\n",
    "  std::cout << \"features = \" << features << \"\\n\";\n",
    "\n",
    "```\n",
    "\n",
    "As we can see there is lot of similarities in the way python code is written and the C++ code is written. This is mainly because the authors of pytorch lib has gone an extra mile to keep the syntax as simple and similar as possible to python, so that the people from python and C++ background can work seemlessly. It is one of the **[philosophy](https://pytorch.org/cppdocs/frontend.html)** behind the pytorh C++ frontend development.\n",
    "\n",
    "\n",
    "**If you observe carfully, if you just copy paste the python code and replace all the **\".\"** with **\"::\"** you have an almost working C++ code!**\n",
    "\n",
    "**NOTE:** Please note that it is an **\"almost working\"** C++ code. We will visit on this topic soon. Till then just assume you can always copy paste the python code and replace the \".\" with \"::\" to get going with your C++ migration of python code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building C++ code using Cmake.\n",
    "\n",
    "### Create CMakeLists.txt file  \n",
    "\n",
    "C++ code can be easily integrated with the pytorch libs using **[Cmake](https://cmake.org/)**. Let us see how to write one for our example. \n",
    "\n",
    "```cmake\n",
    "CMAKE_MINIMUM_REQUIRED(VERSION 3.0 FATAL_ERROR)\n",
    "\n",
    "PROJECT(HelloPytorch) \n",
    "    \n",
    "SET(CMAKE_CXX_STANDARD 11)\n",
    "SET(TORCH_DIR /opt/pytorch/)\n",
    "    \n",
    "FIND_PACKAGE(Torch REQUIRED)\n",
    "    \n",
    "INCLUDE_DIRECTORIES(${TORCH_INCLUDE_DIRS})\n",
    "\n",
    "ADD_EXECUTABLE(HelloWorld main.cpp)\n",
    "TARGET_LINK_LIBRARIES(HelloWolrd \"${TORCH_LIBRARIES}\")\n",
    "\n",
    "```\n",
    "\n",
    "If you understand the Cmake syntax, you can skip over to the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us try to understand what is happening with our **CMakeLists.txt** file and how everything is put together.\n",
    "\n",
    "We specify the minimum version of Cmake required.\n",
    "```cmake\n",
    "CMAKE_MINIMUM_REQUIRED(VERSION 3.0 FATAL_ERROR)\n",
    "```\n",
    "\n",
    "Let us give some name to our project.\n",
    "```cmake\n",
    "PROJECT(HelloPytorch) \n",
    "```\n",
    "\n",
    "libPytorch requires you to compile to code using compiler which supports C++11 or greater. This is how we let the compiler to enable the **--std=c++11** flag during compilation.\n",
    "```cmake\n",
    "SET(CMAKE_CXX_STANDARD 11)\n",
    "```\n",
    "\n",
    "This one is optional. Initially we unzipped the libpytorch.zip file in to **\"/opt/pytorch\"** dirctory. We are hinting the Cmake about where to look for the pytorch dependencies. Ideally Cmake should be able to find the packages by itself. If the compilation is failing then it is good idea to set this flag to help the Cmake to identify where and which version of libpytorch to find.\n",
    "```cmake\n",
    "SET(TORCH_DIR /opt/pytorch/)\n",
    "```\n",
    "\n",
    "The following line does all the magic of finding the required dependencies for our project related to libpytorch.\n",
    "```cmake\n",
    "FIND_PACKAGE(Torch REQUIRED)\n",
    "```\n",
    "\n",
    "Include the pytorch directories.\n",
    "```cmake\n",
    "INCLUDE_DIRECTORIES(${TORCH_INCLUDE_DIRS})\n",
    "```\n",
    "\n",
    "Let us create an executable named \"HelloWorld\" from our main.cpp file.\n",
    "\n",
    "```cmake\n",
    "ADD_EXECUTABLE(HelloWorld main.cpp)\n",
    "```\n",
    "\n",
    "This is how we let the compiler know which libs to use to link our binary. In this case **libpytorch.so**\n",
    "```cmake\n",
    "TARGET_LINK_LIBRARIES(HelloWolrd \"${TORCH_LIBRARIES}\")\n",
    "```\n",
    "\n",
    "### Build\n",
    "\n",
    "Here is the list of commands to be executed to generate the binary.\n",
    "\n",
    "```bash\n",
    "mkdir build\n",
    "cd build\n",
    "cmake ..\n",
    "make\n",
    "```\n",
    "\n",
    "If the build goes fine new find a binary named **HelloWorld** being generated in **build** directory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output\n",
    "\n",
    "### Python\n",
    "```python\n",
    "tensor([[-0.1468,  0.7861,  0.9468, -1.1143,  1.6908]])\n",
    "```\n",
    "\n",
    "### C++\n",
    "```cpp\n",
    "\n",
    "./HelloWorld\n",
    "\n",
    "features =  0.6558  0.3020  0.4799  0.7774  0.9180\n",
    "[ Variable[CPUFloatType]{1,5} ]\n",
    "\n",
    "```\n",
    "Since we are generating random numbers it is expected to be different. There are different ways to print a.k.a **\"pretty prints\"** the tensor using C++, which we will discuss as and when we find the need to use one."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37_django",
   "language": "python",
   "name": "py37_django"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
